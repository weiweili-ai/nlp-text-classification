{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://huggingface.co/learn/nlp-course/zh-CN/chapter2/4\n",
    "tokenizer 是 NLP 管道的核心组件之一。它们有一个非常明确的目的：将文本转换为模型可以处理的数据。模型只能处理数字，因此 tokenizer 需要将我们的文本输入转换为数字. 目标是找到最有意义的表达方式 —— 即对模型来说最有意义的方式 —— 如果可能，还要找到最简洁的表达方式.\n",
    "\n",
    "将文本翻译成数字被称为编码（encoding）。编码分两步完成：分词，然后转换为 inputs ID。\n",
    "第一步是将文本拆分为单词（或部分单词、标点符号等），通常称为 tokens. 不同的分词器使用的算法也不一样，这就是为什么我们需要使用模型名称来实例化 tokenizer，以确保我们使用模型预训练时使用的相同的算法。\n",
    "\n",
    "第二步是将这些 tokens 转换为数字，这样我们就可以用它们构建一个张量并将它们提供给模型。为此，tokenizer 有一个词汇表（vocabulary），这是我们在使用 from_pretrained() 方法实例化它时下载的部分。同样，我们需要使用与预训练模型时相同的词汇表。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加载和保存 tokenizer 就像使用模型一样简单。它基于相同的两种方法： from_pretrained() 和 save_pretrained() 。这些方法会加载或保存分词器使用的算法（有点像模型的架构（architecture））以及其词汇表（有点像模型的权重（weights））。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6e21ce2ae54f15b41e75a69831810a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c68f28b0575441e8562fc87b879222f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4008c939ee848fab15c02f91d1a6d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "782c127bbd9546058d4cf8f4f047f342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efceb3e10ecb4c75a99ddf242abc1f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import BertTokenizer\n",
    "tokenizer_1 = BertTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "from transformers import AutoTokenizer\n",
    "# tokenizer_1 = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "tokenizer_2 = AutoTokenizer.from_pretrained(\"gpt2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 7993, 170, 13809, 23763, 2443, 1110, 3014, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_1(\"Using a Transformer network is simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [12814, 257, 3602, 16354, 3127, 318, 2829], 'attention_mask': [1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer_2(\"Using a Transformer network is simple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./tokenizer_gpt2/tokenizer_config.json',\n",
       " './tokenizer_gpt2/special_tokens_map.json',\n",
       " './tokenizer_gpt2/vocab.json',\n",
       " './tokenizer_gpt2/merges.txt',\n",
       " './tokenizer_gpt2/added_tokens.json',\n",
       " './tokenizer_gpt2/tokenizer.json')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 保存 tokenizer 与保存模型完全相同\n",
    "tokenizer_1.save_pretrained(\"./tokenizer_bert\") #directory_on_my_computer\n",
    "tokenizer_2.save_pretrained(\"./tokenizer_gpt2\") #directory_on_my_computer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "详解如何分词以及转化成数字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert tokenizer: \n",
      " ['Using', 'a', 'Trans', '##former', 'network', 'is', 'simple']\n",
      "gpt2 tokenizer: \n",
      " ['Using', 'Ġa', 'ĠTrans', 'former', 'Ġnetwork', 'Ġis', 'Ġsimple']\n"
     ]
    }
   ],
   "source": [
    "#分词： tokens\n",
    "text = \"Using a Transformer network is simple\"\n",
    "tokens1 = tokenizer_1.tokenize(text)\n",
    "print(\"bert tokenizer: \\n\", tokens1)\n",
    "tokens2 = tokenizer_2.tokenize(text)\n",
    "print(\"gpt2 tokenizer: \\n\", tokens2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert:  [7993, 170, 13809, 23763, 2443, 1110, 3014]\n",
      "gpt2:  [12814, 257, 3602, 16354, 3127, 318, 2829]\n"
     ]
    }
   ],
   "source": [
    "# from tokens to input ids - inputs ID 的转换由 tokenizer 的 convert_tokens_to_ids() 方法实现\n",
    "ids_bert = tokenizer_1.convert_tokens_to_ids(tokens1)   \n",
    "print(\"bert: \", ids_bert)\n",
    "ids_gpt2 = tokenizer_2.convert_tokens_to_ids(tokens2)\n",
    "print(\"gpt2: \", ids_gpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is encoding: from text to input ids; Decoding is the opposite: from input ids to text, which can be done with tokenizer.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert:  surge ë finger functionality\n",
      "gpt2:  Using a Transformer\n"
     ]
    }
   ],
   "source": [
    "decode_string_bert = tokenizer_1.decode([12814, 257, 3602, 16354])\n",
    "print(\"bert: \", decode_string_bert)\n",
    "decode_string_gpt2 = tokenizer_2.decode([12814, 257, 3602, 16354])\n",
    "print(\"gpt2: \", decode_string_gpt2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请注意， decode 方法不仅将索引转换回 tokens，还将属于相同单词的 tokens 组合在一起以生成可读的句子。当我们使用预测新文本的模型（根据提示生成的文本，或序列到序列问题（如翻译或摘要））时，这样的功能将非常有用。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
